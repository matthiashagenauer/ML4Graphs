{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.datasets import Planetoid, Reddit\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import os.path as osp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqkR4SCqKX_h",
        "outputId": "e2cbe684-ad6c-4b10-b177-67790e161277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_CONFIG = {\n",
        "    'Cora': {\n",
        "        'hidden_channels': 32,\n",
        "        'sample_size': 512,\n",
        "        'lr': 0.005,\n",
        "        'weight_decay': 5e-4,\n",
        "        'epochs': 200,\n",
        "        'heads': 4,\n",
        "        'warmup_epochs': 10,\n",
        "        'log_interval': 20,\n",
        "        'root': '/tmp/Cora'\n",
        "    },\n",
        "    'Pubmed': {\n",
        "        'hidden_channels': 64,\n",
        "        'sample_size': 3000,\n",
        "        'lr': 0.01,\n",
        "        'weight_decay': 5e-4,\n",
        "        'epochs': 200,\n",
        "        'heads': 4,\n",
        "        'warmup_epochs': 10,\n",
        "        'log_interval': 20,\n",
        "        'root': '/tmp/Pubmed'\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "TrxVs_AqKo_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(name):\n",
        "    cfg = DATASET_CONFIG[name]\n",
        "\n",
        "    if name == 'Reddit':\n",
        "        dataset = Reddit(root=cfg['root'])\n",
        "        data = dataset[0]\n",
        "\n",
        "        return dataset, data\n",
        "\n",
        "    else: # Cora or Pubmed\n",
        "        dataset = Planetoid(root=cfg['root'], name=name)\n",
        "        data = dataset[0]\n",
        "        data.train_mask = ~(data.val_mask | data.test_mask)\n",
        "\n",
        "        return dataset, data"
      ],
      "metadata": {
        "id": "5kmitDI2KcSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadFastGateLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, heads=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.out_per_head = out_channels // heads\n",
        "\n",
        "        #linear projections and attention vectors for each head\n",
        "        self.W = nn.ModuleList([nn.Linear(in_channels, self.out_per_head, bias=False) for _ in range(heads)])\n",
        "        self.a = nn.ModuleList([nn.Linear(2 * self.out_per_head, 1, bias=False) for _ in range(heads)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index, sampled_nodes, target_nodes, probs, num_nodes, precomputed_alpha=None):\n",
        "        out_heads = []\n",
        "\n",
        "        for h in range(self.heads):\n",
        "            h_x = self.W[h](x)  # projected features for this head\n",
        "\n",
        "            # build masks for target nodes and sampled neighbors\n",
        "            target_mask = torch.zeros(num_nodes, dtype=torch.bool, device=x.device)\n",
        "            sample_mask = torch.zeros(num_nodes, dtype=torch.bool, device=x.device)\n",
        "            target_mask[target_nodes] = True\n",
        "            sample_mask[sampled_nodes] = True\n",
        "\n",
        "            row, col = edge_index\n",
        "            mask = target_mask[row] & sample_mask[col]\n",
        "            row_m, col_m = row[mask], col[mask]\n",
        "            h_v, h_u = h_x[row_m], h_x[col_m]\n",
        "\n",
        "            # compute attention/gate\n",
        "            if precomputed_alpha is None:\n",
        "                e_vu = self.a[h](torch.cat([h_v, h_u], dim=1)).squeeze()\n",
        "                gate = torch.sigmoid(e_vu)\n",
        "                gate = gate / (probs[col_m] + 1e-12)\n",
        "                gate = self.dropout(gate)\n",
        "            else:\n",
        "                gate = precomputed_alpha[mask]\n",
        "\n",
        "            unique_targets = torch.unique(target_nodes, sorted=True)\n",
        "            target_map = torch.full((num_nodes,), -1, device=x.device)\n",
        "            target_map[unique_targets] = torch.arange(unique_targets.size(0), device=x.device)\n",
        "            valid_mask = target_map[row_m] >= 0\n",
        "            local_row = target_map[row_m[valid_mask]]\n",
        "            h_u = h_u[valid_mask]\n",
        "            gate = gate[valid_mask]\n",
        "\n",
        "            # aggregate with degree-normalization\n",
        "            out_local = torch.zeros(unique_targets.size(0), self.out_per_head, device=x.device)\n",
        "\n",
        "            # Compute sum of attention per target node\n",
        "            deg_v = torch.zeros(unique_targets.size(0), device=x.device)\n",
        "            deg_v.index_add_(0, local_row, gate)\n",
        "\n",
        "            # Weighted sum\n",
        "            out_local.index_add_(0, local_row, gate.unsqueeze(1) * h_u)\n",
        "\n",
        "            out_local = out_local / (deg_v.unsqueeze(1) + 1e-6)\n",
        "\n",
        "            # Residual connection\n",
        "            out_local = out_local + h_x[unique_targets]\n",
        "\n",
        "\n",
        "            out_global = torch.zeros(num_nodes, self.out_per_head, device=x.device)\n",
        "            out_global[unique_targets] = out_local\n",
        "            out_heads.append(out_global)\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = torch.cat(out_heads, dim=1)\n",
        "        return out  # shape = num_nodes, out_channels\n",
        "\n",
        "\n",
        "class MultiHeadFastGateModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, sample_size, heads=4):\n",
        "        super().__init__()\n",
        "        self.sample_size = sample_size\n",
        "        self.heads = heads\n",
        "        self.lin1 = nn.Linear(in_channels, hidden_channels, bias=False)\n",
        "        self.conv1 = MultiHeadFastGateLayer(hidden_channels, hidden_channels, heads=heads)\n",
        "        self.conv2 = MultiHeadFastGateLayer(hidden_channels, out_channels, heads=1)  # single head for output\n",
        "\n",
        "    def forward(self, x_pre, edge_index, probs, target_nodes, num_nodes, precomputed_alpha=None):\n",
        "        h = F.relu(self.lin1(x_pre))\n",
        "\n",
        "        # Sample neighbors\n",
        "        if self.training:\n",
        "            sampled = torch.multinomial(probs, self.sample_size, replacement=True)\n",
        "        else:\n",
        "            sampled = torch.arange(num_nodes, device=x_pre.device)\n",
        "\n",
        "        h = F.relu(self.conv1(h, edge_index, sampled, target_nodes, probs, num_nodes, precomputed_alpha))\n",
        "        h = self.conv2(h, edge_index, sampled, target_nodes, probs, num_nodes, precomputed_alpha)\n",
        "\n",
        "        return F.log_softmax(h[target_nodes], dim=1)\n"
      ],
      "metadata": {
        "id": "0CIOjMTlAZWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# load data\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0].to(device)\n",
        "\n",
        "\n",
        "edge_index, _ = add_self_loops(\n",
        "    data.edge_index, num_nodes=data.num_nodes\n",
        ")\n",
        "\n",
        "\n",
        "row, col = edge_index\n",
        "deg = torch.zeros(data.num_nodes, device=device)\n",
        "deg.index_add_(0, row, torch.ones(row.size(0), device=device))\n",
        "probs = deg / deg.sum()\n",
        "probs = probs.clamp(min=1e-4)\n",
        "probs = probs / probs.sum()\n",
        "\n",
        "#precompute\n",
        "norm = 1.0 / torch.sqrt(deg[row] * deg[col])\n",
        "x_precomputed = torch.zeros_like(data.x)\n",
        "x_precomputed.index_add_(0, row, norm.unsqueeze(1) * data.x[col])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDf_TsIyAttP",
        "outputId": "334d5134-40fa-41db-895c-9ccceb1297af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2236, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_CHANNELS = 32\n",
        "SAMPLE_SIZE = 256\n",
        "LR = 0.005\n",
        "WEIGHT_DECAY = 5e-4\n",
        "EPOCHS = 300\n",
        "WARMUP_EPOCHS = 10\n",
        "HEADS = 4\n",
        "\n",
        "model = MultiHeadFastGateModel(\n",
        "    in_channels=dataset.num_features,\n",
        "    hidden_channels=HIDDEN_CHANNELS,\n",
        "    out_channels=dataset.num_classes,\n",
        "    sample_size=SAMPLE_SIZE,\n",
        "    heads=HEADS\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")"
      ],
      "metadata": {
        "id": "eeH2L-uFIae-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FjJvYuWAO1P"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(epochs=EPOCHS):\n",
        "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
        "    val_idx   = data.val_mask.nonzero(as_tuple=False).view(-1)\n",
        "    test_idx  = data.test_mask.nonzero(as_tuple=False).view(-1)\n",
        "\n",
        "    train_idx = torch.sort(train_idx)[0]\n",
        "    val_idx   = torch.sort(val_idx)[0]\n",
        "    test_idx  = torch.sort(test_idx)[0]\n",
        "\n",
        "    precomputed_alpha = None\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            with torch.no_grad():\n",
        "                h = F.relu(model.lin1(x_precomputed))\n",
        "                attention_list = []\n",
        "                for head in range(model.conv1.heads):\n",
        "                    h_v = model.conv1.W[head](h)[edge_index[0]]\n",
        "                    h_u = model.conv1.W[head](h)[edge_index[1]]\n",
        "                    e_vu = model.conv1.a[head](torch.cat([h_v, h_u], dim=1)).squeeze()\n",
        "                    attention_list.append(torch.sigmoid(e_vu))\n",
        "                precomputed_alpha = torch.mean(torch.stack(attention_list), dim=0)\n",
        "\n",
        "        out = model(x_precomputed, edge_index, probs, train_idx, data.num_nodes, precomputed_alpha)\n",
        "        loss = F.nll_loss(out, data.y[train_idx])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_out = model(x_precomputed, edge_index, probs, val_idx, data.num_nodes)\n",
        "                val_acc = (val_out.argmax(dim=1) == data.y[val_idx]).float().mean()\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_out = model(x_precomputed, edge_index, probs, test_idx, data.num_nodes)\n",
        "                test_acc = (test_out.argmax(dim=1) == data.y[test_idx]).float().mean()\n",
        "            print(f\"Epoch {epoch:03d} | Loss {loss:.4f} | Val Acc {val_acc:.4f} | Test Acc {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_out = model(x_precomputed, edge_index, probs, test_idx, data.num_nodes)\n",
        "        test_acc = (test_out.argmax(dim=1) == data.y[test_idx]).float().mean()\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX_dcLmcIggZ",
        "outputId": "4f44b364-a868-4098-9f3c-64e1192ff3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss 1.2510 | Val Acc 0.6560 | Test Acc 0.6770\n",
            "Epoch 020 | Loss 0.3624 | Val Acc 0.7440 | Test Acc 0.7580\n",
            "Epoch 030 | Loss 0.1061 | Val Acc 0.7080 | Test Acc 0.7340\n",
            "Epoch 040 | Loss 0.0301 | Val Acc 0.7040 | Test Acc 0.7410\n",
            "Epoch 050 | Loss 0.0128 | Val Acc 0.6920 | Test Acc 0.7380\n",
            "Epoch 060 | Loss 0.0097 | Val Acc 0.7140 | Test Acc 0.7430\n",
            "Epoch 070 | Loss 0.1273 | Val Acc 0.6960 | Test Acc 0.7390\n",
            "Epoch 080 | Loss 0.0084 | Val Acc 0.7040 | Test Acc 0.7300\n",
            "Epoch 090 | Loss 0.0102 | Val Acc 0.7220 | Test Acc 0.7600\n",
            "Epoch 100 | Loss 0.0167 | Val Acc 0.7000 | Test Acc 0.7400\n",
            "Epoch 110 | Loss 0.0993 | Val Acc 0.7180 | Test Acc 0.7620\n",
            "Epoch 120 | Loss 0.0397 | Val Acc 0.7100 | Test Acc 0.7400\n",
            "Epoch 130 | Loss 0.0743 | Val Acc 0.7040 | Test Acc 0.7490\n",
            "Epoch 140 | Loss 0.0523 | Val Acc 0.7000 | Test Acc 0.7390\n",
            "Epoch 150 | Loss 0.1176 | Val Acc 0.7060 | Test Acc 0.7520\n",
            "Epoch 160 | Loss 0.0283 | Val Acc 0.6800 | Test Acc 0.7240\n",
            "Epoch 170 | Loss 0.0129 | Val Acc 0.6960 | Test Acc 0.7540\n",
            "Epoch 180 | Loss 0.0159 | Val Acc 0.6540 | Test Acc 0.7030\n",
            "Epoch 190 | Loss 0.0274 | Val Acc 0.6820 | Test Acc 0.7220\n",
            "Epoch 200 | Loss 0.0115 | Val Acc 0.6840 | Test Acc 0.7360\n",
            "Epoch 210 | Loss 0.0233 | Val Acc 0.6960 | Test Acc 0.7360\n",
            "Epoch 220 | Loss 0.0338 | Val Acc 0.7020 | Test Acc 0.7440\n",
            "Epoch 230 | Loss 0.0147 | Val Acc 0.6760 | Test Acc 0.7230\n",
            "Epoch 240 | Loss 0.0241 | Val Acc 0.6820 | Test Acc 0.7110\n",
            "Epoch 250 | Loss 0.0092 | Val Acc 0.6760 | Test Acc 0.7250\n",
            "Epoch 260 | Loss 0.0332 | Val Acc 0.6800 | Test Acc 0.7260\n",
            "Epoch 270 | Loss 0.0230 | Val Acc 0.6860 | Test Acc 0.7380\n",
            "Epoch 280 | Loss 0.0106 | Val Acc 0.6900 | Test Acc 0.7430\n",
            "Epoch 290 | Loss 0.0083 | Val Acc 0.6980 | Test Acc 0.7420\n",
            "Epoch 300 | Loss 0.0224 | Val Acc 0.6960 | Test Acc 0.7520\n",
            "------------------------------\n",
            "Final Test Accuracy: 0.7520\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7520)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1  heads: Final Test Accuracy: 0.7510\n",
        "#2  heads: Final Test Accuracy: 0.7580\n",
        "#4  heads: Final Test Accuracy: 0.7340\n",
        "#8  heads: Final Test Accuracy: 0.7460\n",
        "#16 heads: Final Test Accuracy: 0.7500\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3XqDHYByK_f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoeTVBr43p-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}